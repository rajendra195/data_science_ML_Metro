{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a38734",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "<li>Pandas is an open-source Python package that is built on top of NumPy used for working with data sets.</li> \n",
    "<li>The name \"Pandas\" has a reference to <b>\"Python Data Analysis\".</b></li>\n",
    "<li>Pandas is considered to be one of the best data-wrangling packages.</li>\n",
    "<li>Pandas offers user-friendly, easy-to-use data structures and analysis tools for analyzing, cleaning, exploring and manipulating data.</li>\n",
    "<li>It also functions well with various other data science Python modules.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79079ab0",
   "metadata": {},
   "source": [
    "# Difference Between NumPy & Pandas\n",
    "\n",
    "![](images/pandas_vs_numpy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ede164",
   "metadata": {},
   "source": [
    "## Why Use Pandas?\n",
    "\n",
    "<li>Pandas is known for its exceptional ability to represent and organize data.</li>\n",
    "<li>The Pandas library was created to be able to work with large datasets faster and more efficiently than any other library.</li>\n",
    "<li>It excels at analyzing huge amounts of data.Pandas allows us to analyze big data and make conclusions based on statistical theories.</li>\n",
    "<li>Pandas can clean messy data sets, and make them readable and relevant.</li>\n",
    "<li>By combining the functionality of Matplotlib and NumPy, Pandas offers users a powerful tool for performing <b>data analytics and visualization.</b></li>\n",
    "<li>Data can be imported to Pandas from a variety of file formats, such as Csv, SQL, Excel, and JSON, among others.</li>\n",
    "<li>Pandas is a versatile and marketable skill set for data analysts and data scientists that can gain the attention of employers.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97011979",
   "metadata": {},
   "source": [
    "## Installation Of Pandas\n",
    "<li>Go to your terminal, open and activate your virtual environment and then use the following commands for installing pandas.</li>\n",
    "\n",
    "<code>\n",
    "    pip install pandas\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699b7dc",
   "metadata": {},
   "source": [
    "## Importing Pandas\n",
    "<li>We need to import pandas if we want to create a pandas dataframe and perform any analysis on them.</li>\n",
    "<li>We can import pandas package using the following command:</li>\n",
    "<code>\n",
    "    import pandas as pd\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a52ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4140b6ef",
   "metadata": {},
   "source": [
    "## How To Create A Pandas DataFrame\n",
    "<li>A Pandas DataFrame is a 2 dimensional data structure, like a 2 dimensional array, arranged in a table like structure with rows and columns.</li>\n",
    "<li>We can create a basic pandas dataframe by various methods.</li>\n",
    "<li>Let's discuss some of the methods to create the given dataframes:</li>\n",
    "\n",
    "![](images/dataframe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75cbcf",
   "metadata": {},
   "source": [
    "### 1. From Python Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa62793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Name': ['Prabhat', 'Hari', 'Shyam',\n",
    "                             'Sita', 'Mahima', 'Sunil', 'Bhawana'],\n",
    "                   'Age': [24,34,50,32,18,23,22],\n",
    "                   'Address': ['Manigram', 'Dhanewa', 'Bardaghat', 'Manglapur',\n",
    "                              'Bharatpur', 'Kathmandu', 'Ramechap']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3237ee13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prabhat</td>\n",
       "      <td>24</td>\n",
       "      <td>Manigram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hari</td>\n",
       "      <td>34</td>\n",
       "      <td>Dhanewa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shyam</td>\n",
       "      <td>50</td>\n",
       "      <td>Bardaghat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sita</td>\n",
       "      <td>32</td>\n",
       "      <td>Manglapur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mahima</td>\n",
       "      <td>18</td>\n",
       "      <td>Bharatpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sunil</td>\n",
       "      <td>23</td>\n",
       "      <td>Kathmandu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bhawana</td>\n",
       "      <td>22</td>\n",
       "      <td>Ramechap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age    Address\n",
       "0  Prabhat   24   Manigram\n",
       "1     Hari   34    Dhanewa\n",
       "2    Shyam   50  Bardaghat\n",
       "3     Sita   32  Manglapur\n",
       "4   Mahima   18  Bharatpur\n",
       "5    Sunil   23  Kathmandu\n",
       "6  Bhawana   22   Ramechap"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795c295",
   "metadata": {},
   "source": [
    "### 2. From a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c74d83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([{'Name': 'Prabhat', 'Age': 24, 'Address' : 'Manigram'},\n",
    "                    {'Name': 'Hari', 'Age': 34, 'Address' : 'Dhanewa'},\n",
    "                    {'Name': 'Shyam', 'Age': 50, 'Address' : 'Bardaghat'},\n",
    "                    {'Name': 'Sita', 'Age': 32, 'Address' : 'Manglapur'},\n",
    "                    {'Name': 'Mahima', 'Age': 18, 'Address' : 'Bharatpur'},\n",
    "                    {'Name': 'Sunil', 'Age': 23, 'Address' : 'Kathmandu'},\n",
    "                    {'Name': 'Bhawana', 'Age': 22, 'Address' : 'Ramechap'}\n",
    "                   ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53b09719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prabhat</td>\n",
       "      <td>24</td>\n",
       "      <td>Manigram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hari</td>\n",
       "      <td>34</td>\n",
       "      <td>Dhanewa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shyam</td>\n",
       "      <td>50</td>\n",
       "      <td>Bardaghat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sita</td>\n",
       "      <td>32</td>\n",
       "      <td>Manglapur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mahima</td>\n",
       "      <td>18</td>\n",
       "      <td>Bharatpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sunil</td>\n",
       "      <td>23</td>\n",
       "      <td>Kathmandu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bhawana</td>\n",
       "      <td>22</td>\n",
       "      <td>Ramechap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age    Address\n",
       "0  Prabhat   24   Manigram\n",
       "1     Hari   34    Dhanewa\n",
       "2    Shyam   50  Bardaghat\n",
       "3     Sita   32  Manglapur\n",
       "4   Mahima   18  Bharatpur\n",
       "5    Sunil   23  Kathmandu\n",
       "6  Bhawana   22   Ramechap"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed208bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c2d5b64",
   "metadata": {},
   "source": [
    "### 3. From a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adfc0da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame([('Prabhat', 24, 'Manigram'),\n",
    "                    ('Hari', 34, 'Dhanewa'),\n",
    "                    ('Shyam',50, 'Bardaghat'),\n",
    "                    ('Sita', 32, 'Manglapur'),\n",
    "                    ('Mahima', 18, 'Bharatpur'),\n",
    "                    ('Sunil', 23, 'Kathmandu'),\n",
    "                    ('Bhawana', 22, 'Ramechap')\n",
    "                   ], columns = ['Name', 'Age', 'Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10409ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prabhat</td>\n",
       "      <td>24</td>\n",
       "      <td>Manigram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hari</td>\n",
       "      <td>34</td>\n",
       "      <td>Dhanewa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shyam</td>\n",
       "      <td>50</td>\n",
       "      <td>Bardaghat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sita</td>\n",
       "      <td>32</td>\n",
       "      <td>Manglapur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mahima</td>\n",
       "      <td>18</td>\n",
       "      <td>Bharatpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sunil</td>\n",
       "      <td>23</td>\n",
       "      <td>Kathmandu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bhawana</td>\n",
       "      <td>22</td>\n",
       "      <td>Ramechap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age    Address\n",
       "0  Prabhat   24   Manigram\n",
       "1     Hari   34    Dhanewa\n",
       "2    Shyam   50  Bardaghat\n",
       "3     Sita   32  Manglapur\n",
       "4   Mahima   18  Bharatpur\n",
       "5    Sunil   23  Kathmandu\n",
       "6  Bhawana   22   Ramechap"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0746774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92c8ee6c",
   "metadata": {},
   "source": [
    "### 4. From list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf61d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame([['Prabhat', 24, 'Manigram'],\n",
    "                    ['Hari', 34, 'Dhanewa'],\n",
    "                    ['Shyam',50, 'Bardaghat'],\n",
    "                    ['Sita', 32, 'Manglapur'],\n",
    "                    ['Mahima', 18, 'Bharatpur'],\n",
    "                    ['Sunil', 23, 'Kathmandu'],\n",
    "                    ['Bhawana', 22, 'Ramechap']\n",
    "                   ], columns = ['Name', 'Age', 'Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "922e67e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prabhat</td>\n",
       "      <td>24</td>\n",
       "      <td>Manigram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hari</td>\n",
       "      <td>34</td>\n",
       "      <td>Dhanewa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shyam</td>\n",
       "      <td>50</td>\n",
       "      <td>Bardaghat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sita</td>\n",
       "      <td>32</td>\n",
       "      <td>Manglapur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mahima</td>\n",
       "      <td>18</td>\n",
       "      <td>Bharatpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sunil</td>\n",
       "      <td>23</td>\n",
       "      <td>Kathmandu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bhawana</td>\n",
       "      <td>22</td>\n",
       "      <td>Ramechap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age    Address\n",
       "0  Prabhat   24   Manigram\n",
       "1     Hari   34    Dhanewa\n",
       "2    Shyam   50  Bardaghat\n",
       "3     Sita   32  Manglapur\n",
       "4   Mahima   18  Bharatpur\n",
       "5    Sunil   23  Kathmandu\n",
       "6  Bhawana   22   Ramechap"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a00fa",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "<li>Read 'weather_data.csv' file using csv reader.</li>\n",
    "<li>Store the data inside the csv file into a list of lists.</li>\n",
    "<li>Then create a pandas dataframe using list of list.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91ac7af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['kfjkdfjskd'], ['dfuhsdjufio'], ['day', 'temperature', 'windspeed', 'event'], ['1/1/2017', '32', '6', 'Rain'], ['1/4/2017', 'not available', '9', 'Sunny'], ['1/5/2017', '-1', 'not measured', 'Snow'], ['1/6/2017', 'not available', '7', 'no event'], ['1/7/2017', '32', 'not measured', 'Rain'], ['1/8/2017', 'not available', 'not measured', 'Sunny'], ['1/9/2017', 'not available', 'not measured', 'no event'], ['1/10/2017', '34', '8', 'Cloudy'], ['1/11/2017', '-4', '-1', 'Snow'], ['1/12/2017', '26', '12', 'Sunny'], ['1/13/2017', '12', '12', 'Rainy'], ['1/11/2017', '-1', '12', 'Snow'], ['1/14/2017', '40', '-1', 'Sunny']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "file = open('data/weather_data.csv')\n",
    "file_reader = reader(file)\n",
    "data = list(file_reader)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame(data[1:], columns = data[0])\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c9a6a",
   "metadata": {},
   "source": [
    "#### Question\n",
    "<li>1. Read 'imports-85.data' file using file reader.</li>\n",
    "<li>2. Store the data present inside the file into a list of list.</li>\n",
    "<li>3. Create a pandas dataframe using list of lists.</li>\n",
    "<li>4. For column name, we can use the columns variable given below.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44beda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_data = []\n",
    "# file = open('imports-85.data', 'r')\n",
    "# data_read = file.readlines()\n",
    "# for item in data_read:\n",
    "#     item_list = item.split('\\n')[:-1]\n",
    "#     new_item_list = item[0].split(',')\n",
    "#     total_data.append(new_item_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c928e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c3c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['symboling', 'normalized_losses', 'make', 'fuel_type', 'aspiration', 'num_of_doors',\n",
    "          'body_style', 'drive_wheels', 'engine_location', 'wheel_base', 'length', 'width', \n",
    "           'height', 'curb_weight', 'engine_type', 'num_of_cylinders', 'engine_size', 'fuel_system',\n",
    "          'bore', 'stroke', 'compression', 'horsepower', 'peak_rpm', 'city_mpg', 'highway_mpg', \n",
    "           'price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d8b79",
   "metadata": {},
   "source": [
    "### 5. Pandas Dataframe From Csv files\n",
    "\n",
    "<li>We can load a csv file and create a dataframe out of the data present inside a csv file using pandas.</li>\n",
    "<li>We have <b>.read_csv()</b> method to read a csv file and create a pandas dataframe from the dataset.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ac0ad",
   "metadata": {},
   "source": [
    "### Reading a csv file using skiprows and header parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2715024",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data.csv',skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf99f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data.csv', header = 2)\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a3a1c",
   "metadata": {},
   "source": [
    "#### Reading a csv file without header and giving names to the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data.csv',skiprows = 3, header = None,\n",
    "                        names = ['dates', 'temp', 'ws', 'forecast'])\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b29e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0a3997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e2fb6da",
   "metadata": {},
   "source": [
    "#### Read limited data from a csv file using nrows parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data.csv',skiprows = 3,nrows = 5, header = None,\n",
    "                        names = ['dates', 'temp', 'ws', 'forecast'])\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b269e47",
   "metadata": {},
   "source": [
    "#### Reading csv files with na_values parameters ('weather_data.csv' file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa83c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data.csv',skiprows = 2,\n",
    "#                         na_values = ['not available', 'not measured', \n",
    "#                                     'no event']\n",
    "                        )\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1902ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data.csv',skiprows = 2,\n",
    "                        na_values = {'temperature': 'not available',\n",
    "                                     'windspeed': ['not measured', -1],\n",
    "                                    'event': 'no event'})\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70933041",
   "metadata": {},
   "source": [
    "#### Write a pandas dataframe to a csv file\n",
    "<li>We can write a pandas dataframe to a csv file using .to_csv() method.</li>\n",
    "<li>You can specify any name to the csv file while writing a pandas dataframe into a csv file.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea9b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.to_csv('weather_data_nan.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fcbf58",
   "metadata": {},
   "source": [
    "### 6. Pandas Dataframe From Xcel files\n",
    "\n",
    "<li>We can load an excel file with <b>.xlsx</b> extension and create a dataframe out of the data present inside an excel file using pandas.</li>\n",
    "<li>We have <b>.read_excel()</b> method to read a csv file and create a pandas dataframe from the dataset.</li>\n",
    "<li>We also need to install <b>openpyxl</b> for working with excel files.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad47a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_excel('weather_data.xlsx',\n",
    "                           na_values = {'temperature': 'not available',\n",
    "                                     'windspeed': ['not measured', -1],\n",
    "                                    'event': 'no event'})\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98ce1b",
   "metadata": {},
   "source": [
    "#### Writing to an excel file\n",
    "<li>We can write a pandas dataframe into a excel file using .to_excel() method.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b74d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.to_excel('weather_data.xlsx', 'nans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9e170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa283a0e",
   "metadata": {},
   "source": [
    "#### Using head() and tail() method to see top 5 and last 5 rows\n",
    "<li>To view the first few rows of our dataframe, we can use the DataFrame.head() method.</li>\n",
    "<li>By default, it returns the first five rows of our dataframe.</li>\n",
    "<li>However, it also accepts an optional integer parameter, which specifies the number of rows.</li>\n",
    "\n",
    "<li>Similarly, to view the last few rows of our dataframe, we can use the DataFrame.tail() method.</li>\n",
    "<li>By default, it returns the last five rows of our dataframe.</li>\n",
    "<li>However, it also accepts an optional integer parameter, which specifies the number of rows.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data.csv', skiprows = 2)\n",
    "weather_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64efe833",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69ce71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1955ec8",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "\n",
    "<li>Use the head() method to select the first 6 rows.</li>\n",
    "<li>Use the tail() method to select the last 8 rows.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd60da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61fb21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823ed4e",
   "metadata": {},
   "source": [
    "#### Finding the column names from the dataframe\n",
    "<li>We have df.columns attributes to check the name of columns in the pandas dataframe.</li>\n",
    "<li>Similarly, we have df.values attributes to check the data present in the pandas dataframe.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4cf474",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9998b20b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weather_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[43mweather_df\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weather_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(type(weather_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121196c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.columns[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d870a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(weather_df.columns)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bbcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(weather_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd19f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ff0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.values.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2108265",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d686e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.values[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0731077",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.values[weather_df.values[:,-1] == 'Sunny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fbbaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.values[weather_df.values[:,1] == 'not available']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.values[weather_df.values[:,2] == 'not measured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5843df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.values[weather_df.values[:,-1] == 'no event']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f4e92",
   "metadata": {},
   "source": [
    "#### Checking the type of your dataframe \n",
    "<li>Another feature that makes pandas better for working with data is that dataframes can contain more than one data type.</li>\n",
    "<li>Axis values can have string labels, not just numeric ones.</li>\n",
    "<li>Dataframes can contain columns with multiple data types: including integer, float, and string.</li>\n",
    "<li>We can use the DataFrame.dtypes attribute (similar to NumPy) to return information about the types of each column.</li>\n",
    "<li>When we import data, pandas attempts to guess the correct dtype for each column.</li>\n",
    "<li>Generally, pandas does well with this, which means we don't need to worry about specifying dtypes every time we start to work with data.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632901d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_nan = pd.read_csv('weather_data_nan.csv')\n",
    "weather_df_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7209ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_nan.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1518ae8e",
   "metadata": {},
   "source": [
    "#### Datatypes Information\n",
    "<li>We can get the shape of the dataset using <b>.shape()</b> method.</li>\n",
    "<li><b>.shape()</b> method returns the tuple datatype containing the number of rows and number of columns in the dataset.</li>\n",
    "<li>If we wanted an overview of all the dtypes used in our dataframe, we can use <b>.info()</b> method.</li>\n",
    "<li>Note that <b>DataFrame.info()</b> prints the information, rather than returning it, so we can't assign it to a variable.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06281976",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_nan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf679a",
   "metadata": {},
   "source": [
    "#### Checking the null values in the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960ae61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_nan.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444a637",
   "metadata": {},
   "source": [
    "#### set_index() and reset_index() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_nan = pd.read_csv('weather_data_nan.csv',\n",
    "                             parse_dates = ['day'])\n",
    "weather_df_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46949e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_nan.set_index('day', inplace = True)\n",
    "weather_df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_nan.reset_index(inplace = True)\n",
    "weather_df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_index_df = weather_df_nan.set_index('temperature')\n",
    "temperature_index_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64149a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_reset_index_df = temperature_index_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d88f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_reset_index_df.reset_index(inplace = True)\n",
    "temperature_reset_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5f12d48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temperature_reset_index_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtemperature_reset_index_df\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m temperature_reset_index_df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temperature_reset_index_df' is not defined"
     ]
    }
   ],
   "source": [
    "temperature_reset_index_df.reset_index(inplace = True, drop = True)\n",
    "temperature_reset_index_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60c853",
   "metadata": {},
   "source": [
    "#### Selecting a column from a pandas DataFrame\n",
    "\n",
    "<li>Since our axis in pandas have labels, we can select data using those labels.</li> \n",
    "<li>Unlike in NumPy, we donot need to know the exact index location of a pandas dataframe.</li>\n",
    "<li>To do this, we can use the DataFrame.loc[] attribute. The syntax for DataFrame.loc[] is:</li>\n",
    "<code>\n",
    "df.loc[row_label, column_label]\n",
    "</code>\n",
    "\n",
    "<li>We can use the following shortcut to select a single column:</li>\n",
    "<code>\n",
    "df[\"column_name\"]\n",
    "</code>\n",
    "\n",
    "<li>This style of selecting columns is very common.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "weather_df = pd.read_csv('weather_data_nan.csv')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef16700",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.loc[:, 'event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc36179",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89546f82",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "<li>Read <b>'appointment_schedule.csv'</b> file using pandas.</li>\n",
    "<li>Select the <b>'name'</b> column from the given dataset and store to <b>'appointment_names'</b> variable.</li>\n",
    "<li>Use Python's <b>type()</b> function to assign the type of name column to <b>name_type</b>.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e41dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_df = pd.read_csv('appointment_schedule.csv')\n",
    "appointment_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a087347",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77564d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_names = appointment_df.loc[:,'name']\n",
    "print(appointment_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_names = appointment_df['name']\n",
    "print(appointment_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb7a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(appointment_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9570baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc59c3",
   "metadata": {},
   "source": [
    "#### Pandas Series\n",
    "<li>Series is the pandas type for one-dimensional objects.</li>\n",
    "<li>Anytime you see a 1D pandas object, it will be a series. Anytime you see a 2D pandas object, it will be a dataframe.</li>\n",
    "<li>A dataframe is a collection of series objects, which is similar to how pandas stores the data behind the scenes.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe1187",
   "metadata": {},
   "source": [
    "#### Adding a column in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86841207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weather_df['is_play'] = np.nan\n",
    "print(weather_df.shape)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d7a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_play = weather_df['is_play']\n",
    "print(type(is_play))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97247ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410deeaa",
   "metadata": {},
   "source": [
    "### Selecting Multiple Columns From the DataFrame\n",
    "\n",
    "![](images/selecting_columns.png)\n",
    "\n",
    "<li>We can select multiple columns from the dataframe by using the following codes:</li>\n",
    "<code>\n",
    "    df.loc[:, [\"col1\", \"col2\"]]\n",
    "</code>\n",
    "\n",
    "<li>We can use syntax shortcuts for selecting multiple columns by using the following syntax:</li>\n",
    "<code>\n",
    "    df[[\"col1\", \"col2\"]]\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data_nan.csv', parse_dates = ['day'])\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.set_index('day', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c5ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.loc[:, [\"temperature\", \"event\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52683472",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[['temperature', 'event']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aae255",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_no_windspeed = weather_df.drop('windspeed', axis = 1)\n",
    "weather_df_no_windspeed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30922f64",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "<li>Read 'car_details.csv' file and create a pandas dataframe from it.</li>\n",
    "<li>Then only select <b>'name'</b>, <b>'selling price'</b> and <b>'km_driven'</b> columns from the dataframe.</li>\n",
    "\n",
    "![](images/selecting_3_cols.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0439cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df = pd.read_csv('car_details.csv')\n",
    "car_details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f78cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[:, ['name', 'selling_price', 'km_driven']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2356fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df[['name', 'selling_price', 'km_driven']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_limited = car_details_df.drop(['year', 'fuel', 'seller_type',\n",
    "                                          'transmission', 'owner'],\n",
    "                                          axis = 1)\n",
    "car_details_limited.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bb5f7",
   "metadata": {},
   "source": [
    "#### Selecting Rows From A Pandas DataFrame\n",
    "\n",
    "<li>Now that we've learned how to select columns by label, let's learn how to select rows using the labels of the index axis.</li>\n",
    "<li>We can use the same syntax to select rows from a dataframe as we do for columns:</li>\n",
    "<code>\n",
    "    df.loc[row_label, column_label]\n",
    "</code>\n",
    "\n",
    "![](images/selecting_one_row.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.loc['2017-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f49d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.reset_index(inplace = True)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09302869",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weather_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mweather_df\u001b[49m\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m weather_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weather_df' is not defined"
     ]
    }
   ],
   "source": [
    "weather_df.set_index('temperature', inplace = True)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb569ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.loc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accea984",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.reset_index(inplace = True)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc570bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.set_index('event', inplace = True)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.loc[\"Sunny\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb7ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9abbbda2",
   "metadata": {},
   "source": [
    "### Selecting Multiple Rows From the DataFrame\n",
    "\n",
    "![](images/selecting_multiple_rows.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_df.reset_index().set_index('day')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.loc[['2017-01-01', '2017-01-04']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95af496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb6b1bca",
   "metadata": {},
   "source": [
    "#### Indexing & Slicing In Pandas DataFrame\n",
    "\n",
    "<li>We can slice a dataset from their rows as well as columns.</li>\n",
    "<li>If we have (5,5) shape data and we want first three rows and first three columns then we need to slice both rows and columns to get a desired shape.</li>\n",
    "<li>We have df.iloc() method which we can use to do indexing as well as slicing in a dataframe.</li>\n",
    "<li>Let's practice .iloc() method.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce094ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49582413",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.iloc[2:5, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812def57",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.iloc[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14098a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.iloc[11,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2a6a6",
   "metadata": {},
   "source": [
    "#### Datatype Conversion In Pandas\n",
    "\n",
    "<li>Pandas astype() is the one of the most important methods. It is used to change data type of a series.</li>\n",
    "<li>When a pandas dataframe is created from a csv file,the data type is set automatically.</li>\n",
    "<li>The datatype will not be what it actually should be at times and this is where we can use astype()  to get desired datatype.</li>\n",
    "<li>For example, a salary column could be imported as string but to do operations we have to convert it into float.</li>\n",
    "<li>astype() is used to do such data type conversions.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['day'] = weather_df['day'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee171577",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb75691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "car_df = pd.read_csv('car_details.csv')\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a02008",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df[['selling_price', 'km_driven']] = car_df[['selling_price', 'km_driven']].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e22cf7",
   "metadata": {},
   "source": [
    "#### Value Counts Method\n",
    "\n",
    "<li>Since series and dataframes are two distinct objects, they have their own unique methods.</li>\n",
    "\n",
    "<li>Let's look at an example of a series method - the Series.value_counts() method.</li>\n",
    "\n",
    "<li>This method displays each unique non-null value in a column and their counts in order.</li>\n",
    "\n",
    "<li>value_counts() is a series only method, we get the following error if we try to use it for dataframes:</li>\n",
    "\n",
    "<code>\n",
    "    AttributeError: 'DataFrame' object has no attribute 'value_counts'\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data_nan.csv')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['windspeed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = pd.read_csv('car_details.csv')\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbbd95bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcar_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'car_df' is not defined"
     ]
    }
   ],
   "source": [
    "car_df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['fuel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e21f7",
   "metadata": {},
   "source": [
    "#### Creating a frequency table from value_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624debf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_count_df = car_df['fuel'].value_counts().to_frame()\n",
    "fuel_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a386909",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_count_df.loc['Diesel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_count_df.reset_index(inplace = True)\n",
    "fuel_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5254648",
   "metadata": {},
   "source": [
    "#### Renaming the column names in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_count_df.columns = ['fuel', 'frequency']\n",
    "fuel_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9271d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_count_df.rename({'fuel': 'fuel_type', 'frequency': 'freq'}, \n",
    "                     inplace = True, axis = 1)\n",
    "fuel_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48590a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_count_df(df, exist_col, renamed_cols):\n",
    "    \"\"\"\n",
    "    df -> dataframe (dataframe object),\n",
    "    exist_col -> any feature from the dataframe (string)\n",
    "    renamed_cols -> name of columns you want to rename with (list)\n",
    "    \"\"\"\n",
    "    \n",
    "    freq_count_df = df[exist_col].value_counts().to_frame().reset_index()\n",
    "    freq_count_df.columns = renamed_cols\n",
    "    return freq_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b72368",
   "metadata": {},
   "outputs": [],
   "source": [
    "seller_type, transmission, owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a75e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seller_type_count_df = freq_count_df(df = car_df,\n",
    "                                     exist_col = 'seller_type',\n",
    "                                     renamed_cols = ['seller_type', 'freq']\n",
    "                                    )\n",
    "seller_type_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37682d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_count_df = freq_count_df(df = car_df,\n",
    "                                     exist_col = 'transmission',\n",
    "                                     renamed_cols = ['transmission', 'freq']\n",
    "                                    )\n",
    "transmission_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47004097",
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_count_df = freq_count_df(df = car_df,\n",
    "                                     exist_col = 'owner',\n",
    "                                     renamed_cols = ['owner', 'freq']\n",
    "                                    )\n",
    "owner_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d48a664",
   "metadata": {},
   "source": [
    "#### Selecting Items From A Series Method\n",
    "\n",
    "<li>As with dataframes, we can use Series.loc[] to select items from a series using single labels, a list, or a slice object.</li>\n",
    "<li>We can also omit loc[] and use bracket shortcuts for all three:</li>\n",
    "\n",
    "![](images/selecting_series.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77264a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_count_series = car_df['fuel'].value_counts()\n",
    "fuel_count_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_count_series.loc['Diesel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_count_series.loc[['Diesel', 'Petrol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_count_series.loc[\"Diesel\": \"CNG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36bdfb5",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "<li>Use the value counts method to check the frequency count of different names from 'appointment_schedule.csv' file.</li>\n",
    "<li>Select only first row from the series.</li>\n",
    "<li>Select the first row and the last row from the series.</li>\n",
    "<li>Select the first five rows and the last five rows from the series.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd557b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_df = pd.read_csv('appointment_schedule.csv')\n",
    "appointment_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b833e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_count_series = appointment_df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcbb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_count_series.loc[\"Joshua T. Blanton\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f16ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_count_series.loc[[\"Joshua T. Blanton\", \"Martin O. Reina\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5d6f3",
   "metadata": {},
   "source": [
    "#### DataFrame Vs DataSeries\n",
    "\n",
    "![](images/dataframe_vs_series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a991f",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "![](images/pandas_selection_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58daf32",
   "metadata": {},
   "source": [
    "#### Vecotrized Operations In Pandas\n",
    "\n",
    "<li>We'll explore how pandas uses many of the concepts we learned in the NumPy.</li>\n",
    "<li>Because pandas is designed to operate like NumPy, a lot of concepts and methods from Numpy are supported.</li>\n",
    "<li>Recall that one of the ways NumPy makes working with data easier is with vectorized operations.</li>\n",
    "<li>Just like with NumPy, we can use any of the standard Python numeric operators with series, including:</li>\n",
    "<code>\n",
    "    series_a + series_b - Addition\n",
    "    series_a - series_b - Subtraction\n",
    "    series_a * series_b - Multiplication\n",
    "    series_a / series_b - Division\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d98d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['sp_per_kmdriven'] = car_df['selling_price'] / car_df['km_driven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb67a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['metres_driven'] = car_df['km_driven'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['age_in_years'] = 2023 - car_df['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8c873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d856282",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weather_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m weather_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_in_kelvin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m273\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mweather_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m weather_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weather_df' is not defined"
     ]
    }
   ],
   "source": [
    "weather_df['temp_in_kelvin'] = 273 + weather_df['temperature']\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0db341",
   "metadata": {},
   "source": [
    "#### Some Statistical Functions In Pandas\n",
    "\n",
    "<li>Like NumPy, Pandas supports many descriptive stats methods such as mean, median, mode, min, max and so on.</li>\n",
    "<li>Here are a few of the most useful ones.</li>\n",
    "<code>\n",
    "Series.max()\n",
    "Series.min()\n",
    "Series.mean()\n",
    "Series.median()\n",
    "Series.mode()\n",
    "Series.sum()\n",
    "</code>\n",
    "<li>We can calculate the average value of a particular column(series) using df.column_name.mean().</li>\n",
    "<li>For calculating the minimum value in a particular column(series), we can use df.column_name.min().</li>\n",
    "<li>Similarly, for calculating the maximum value in a particular column(series), we can use df.column_name.max().</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e1abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['selling_price'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba56a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['selling_price'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008cab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['selling_price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e424d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['selling_price'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d1caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['selling_price'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a6c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['selling_price'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['owner'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da45a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['owner'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6ea53",
   "metadata": {},
   "source": [
    "#### Finding the descriptive statistics of the dataframe using .describe() method\n",
    "\n",
    "<li>Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset's distribution, excluding NaN values.</li>\n",
    "<li>describe() method in Pandas is used to compute descriptive statistics for all of your numeric columns.</li>\n",
    "<li>Analyzes both numeric and object series, as well as DataFrame column sets of mixed data types.</li>\n",
    "<li>The output will vary depending on what is provided.</li>\n",
    "<li>If we want to see the descriptive statistics of an object datatype then we have to specify <b>df.describe(include = \"O\")</b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fa382",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.describe(include = \"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168535df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fb2ba4a",
   "metadata": {},
   "source": [
    "#### Assigning Values With Pandas\n",
    "\n",
    "<li>Just like in NumPy, the same techniques that we use to select data could be used for assignment.</li>\n",
    "\n",
    "<li>When we selected a whole column by label and used assignment, we assigned the value to every item in that column.</li>\n",
    "\n",
    "<li>By providing labels for both axes, we can assign them to a single value within our dataframe.</li>\n",
    "\n",
    "<code>\n",
    "    df.loc[row_label, col_label] = assignment_value\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data_nan.csv')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aede61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8916b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.loc[1,'temperature'] = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a076b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.loc[3,[\"temperature\", \"event\"]] = [30, \"Sunny\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206acb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_df.set_index('day')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.loc['1/5/2017', 'windspeed'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5da8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9b17d",
   "metadata": {},
   "source": [
    "#### Using Boolean Indexing With Pandas Objects (Selection With Condition In Pandas)\n",
    "<li>We can assign a value by using row label and column label in pandas.</li>\n",
    "<li>But what if we need to assign a same value to a group of similar rows with the same criteria.</li>\n",
    "<li> Instead, we can use boolean indexing to change all rows that meet the same criteria, just like we did with NumPy.</li>\n",
    "\n",
    "\n",
    "<ol>\n",
    "    <li>Equals: df['series'] == value</li>\n",
    "    <li>Not Equals: df['series'] != value</li>\n",
    "    <li>Less than: df['series'] < value</li>\n",
    "    <li>Less than or equal to: df['series'] <= value</li>\n",
    "    <li>Greater than: df['series'] > value</li>\n",
    "    <li>Greater than or equal to: df['series'] >= value</li>\n",
    "</ol>\n",
    "<li>These conditions can be used in several ways, most commonly inside .loc to select values with conditions.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0019df",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[weather_df['temperature'] > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d34ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[weather_df['event'] == \"Rain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[weather_df['windspeed'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec97c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df = pd.read_csv('car_details.csv')\n",
    "car_details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5722bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maruti_800_ac_df = car_details_df[car_details_df['name'] == \"Maruti 800 AC\"]\n",
    "maruti_800_ac_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "maruti_800_ac_df['selling_price'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183afcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "maruti_800_ac_df['selling_price'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d209213",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maruti_800_ac_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmaruti_800_ac_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselling_price\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'maruti_800_ac_df' is not defined"
     ]
    }
   ],
   "source": [
    "maruti_800_ac_df['selling_price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e954b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df[car_details_df['name'] == \"Maruti 800 AC\"]['selling_price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ec98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[car_details_df['name'] == \"Maruti 800 AC\", \"selling_price\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[car_details_df['year'] == 2012, 'selling_price'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7163471",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[car_details_df['year'] == 2012, 'selling_price'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[car_details_df['year'] == 2012, 'selling_price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[car_details_df['selling_price'] > 100000, \"name\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[car_details_df['selling_price'] < 100000, \"name\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[((car_details_df['selling_price'] < 80000) &\n",
    "                   (car_details_df['owner'] == \"Second Owner\")),\n",
    "                    \"name\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823eb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[((car_details_df['name'] == \"Maruti Swift Dzire VDI\") |\n",
    "                   (car_details_df['name'] == \"Maruti Alto 800 LXI\"))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinNamelist = [\"Maruti Swift Dzire VDI\", \"Maruti Alto 800 LXI\", \"Maruti Alto LXi\",            \n",
    "\"Maruti Alto LX\", \"Hyundai EON Era Plus\", \"Maruti Swift VDI BSIV\",\n",
    " \"Maruti Wagon R VXI BS IV\", \"Maruti Swift VDI\", \"Hyundai EON Magna Plus\",\n",
    " \"Maruti Wagon R LXI Minor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df['top10counts'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd657b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[car_details_df['name'].isin(isinNamelist),\n",
    "               \"top10counts\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c99877",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df['top10counts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7085335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc9f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64feeff6",
   "metadata": {},
   "source": [
    "### Using Pandas Method To Create a Boolean Mask\n",
    "\n",
    "<li>In the last couple lessons, we used Python boolean operators to create boolean masks to select subsets of data.</li>\n",
    "    \n",
    "<li>There are also a number of pandas methods that return boolean masks useful for exploring data.</li>\n",
    "\n",
    "<li>Two examples are the Series.isnull() method and Series.notnull() method.</li>\n",
    "<li>Series.isnull() method can be used to select either rows that contain null (or NaN) values for a certain column.</li>\n",
    "<li>Similarly, Series.notnull() method is used to select rows that do not contain null values for a certain column.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa527d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data_nan.csv')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e72476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[weather_df['temperature'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e80012",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[weather_df['temperature'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[(weather_df['temperature'].notnull()) &\n",
    "(weather_df['windspeed'].notnull()) &\n",
    "(weather_df['event'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a63c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd7f9989",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "<li>Read 'Fortune_1000.csv' file using pandas read_csv() method and store it in a variable named f1000.</li>\n",
    "<li>Select the rank, revenues, and rank_change columns in f1000. Then, use the df.head() method to select first five rows.</li>\n",
    "<li>Select just the fifth row of the f1000 dataframe. Assign the result to fifth_row using iloc.</li>\n",
    "<li>Select the value in first row of the company column. Assign the result to company_value.</li>\n",
    "<li>Select the last three rows of the f1000 dataframe. Assign the result to last_three_rows.</li>\n",
    "<li>Select the first to seventh rows and the first five columns of the f1000 dataframe.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "f1000 = pd.read_csv('Fortune_1000.csv', na_values = \" \")\n",
    "f1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1000.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49522a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfa2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1000_selection = f1000[['rank', 'rank_change', 'revenue']]\n",
    "print(f1000_selection.shape)\n",
    "f1000_selection.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bd0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_row = f1000.iloc[4,:]\n",
    "print(fifth_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_value = f1000.loc[0, 'company']\n",
    "print(company_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_three_rows = f1000[-3:]\n",
    "last_three_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_to_seven_rows = f1000.iloc[:7, :5]\n",
    "first_to_seven_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e903aad",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "<li>Use the Series.isnull() method to select all rows from f1000 that have a null value for the prev_rank column.</li>\n",
    "<li>Select only the company, rank, and previous_rank columns where previous_rank column is null.</li>\n",
    "<li>Use the Series.notnull() method to select all rows from f1000 that have a non-null value for the previous_rank column.</li></b>\n",
    "<li>From the previously_ranked dataframe, subtract the rank column from the previous_rank column.</li>\n",
    "<li>Assign the values in the rank_change to a new column in the f1000 dataframe, \"rank_change\".</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b0d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_prev_rank = f1000[f1000['prev_rank'].isnull()]\n",
    "null_prev_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c148072",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_previous_rank = f1000.loc[f1000['prev_rank'].isnull(),['company', 'rank', 'prev_rank']]\n",
    "null_previous_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c00817",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_prev_rank = f1000[f1000['prev_rank'].notnull()]\n",
    "not_null_prev_rank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b46be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1000['rank_change'] = f1000['prev_rank'] - f1000['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14cdb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b824f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3aa0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e4a3f21",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "<li>Select all companies with revenues over 100 thousands and negative profits from the f1000 dataframe.</li>\n",
    "\n",
    "##### Instructions\n",
    "\n",
    "<li>Create a boolean array that selects the companies with revenues greater than 100 thousands.</li>\n",
    "<li>Create a boolean array that selects the companies with profits less than 0.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c1f94e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1000' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mf1000\u001b[49m[(f1000[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrevenue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100000\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      2\u001b[0m      (f1000[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f1000' is not defined"
     ]
    }
   ],
   "source": [
    "f1000[(f1000['revenue'] > 100000) &\n",
    "     (f1000['profit'] < 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f0aa4",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "<li>Select all rows for companies whose city value is either Brazil or Venezuela.</li>\n",
    "<li>Select the first five companies in the Technology sector for which the city is not the \"Boston\" from the f1000 dataframe.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebd7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1000.loc[(f1000['city'] == \"New York\") |\n",
    "         (f1000['city']==\"San Fransciso\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c4ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1000.loc[(f1000['city'] != \"Boston\")].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e66d65",
   "metadata": {},
   "source": [
    "#### Sorting Values\n",
    "<li>We can use the DataFrame.sort_values() method to sort the rows on a particular column.</li>\n",
    "<li>To do so, we pass the column name to the method:</li>\n",
    "<code>\n",
    "sorted_rows = df.sort_values(\"column_name\")\n",
    "</code>\n",
    "<li>By default, the sort_values() method will sort the rows in ascending order — from smallest to largest.</li>\n",
    "<li>To sort the rows in descending order instead, we can set the ascending parameter to False:</li>\n",
    "<code>\n",
    "    sorted_rows = df.sort_values(\"column_name\", ascending=False)\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data_nan.csv')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.sort_values('temperature', ascending = True, inplace = True)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.sort_values('windspeed', ascending = False, inplace = True)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.sort_values('event', ascending = True, inplace = True)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ddf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1000.sort_values(['rank_change', 'revenue', 'profit'], \n",
    "                 ascending = [True, False, False], inplace = True)\n",
    "f1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea07b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1000.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab79adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9acbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45766113",
   "metadata": {},
   "source": [
    "#### Question\n",
    "<li>Read 'Fortune_1000.csv' using pandas read_csv() method.</li>\n",
    "<li>Find the company headquartered in Los Angeles with the largest number of employees.</li>\n",
    "<li>Select only the rows that have a city name equal to Los Angeles.</li>\n",
    "<li>Use DataFrame.sort_values() to sort those rows by the employees column in descending order.</li>\n",
    "<li>Use DataFrame.iloc[] to select the first row from the sorted dataframe.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1000 = pd.read_csv('Fortune_1000.csv', na_values = \" \")\n",
    "f1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "los_angeles_df = f1000[f1000['city'] == \"Los Angeles\"].sort_values('num. of employees',\n",
    "                                                 ascending = False)\n",
    "los_angeles_df.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed814c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86aa1f3f",
   "metadata": {},
   "source": [
    "### String Manipulation In Pandas DataFrame\n",
    "\n",
    "<li>String manipulation is the process of changing, parsing, splitting, 'cleaning' or analyzing strings.</li>\n",
    "<li>As we know that sometimes, data in the string is not suitable for manipulating the analysis or get a description of the data.</li>\n",
    "<li>But Python is known for its ability to manipulate strings.</li>\n",
    "<li>Pandas provides us the ways to manipulate to modify and process string data-frame using some builtin functions.</li>\n",
    "<li>Some of the most useful pandas string processing functions are as follows:</li>\n",
    "<ol>\n",
    "    <li><b>lower()</b></li>\n",
    "    <li><b>upper()</b></li>\n",
    "    <li><b>islower()</b></li>\n",
    "    <li><b>isupper()</b></li>\n",
    "    <li><b>isnumeric()</b></li>\n",
    "    <li><b>strip()</b></li>\n",
    "    <li><b>split()</b></li>\n",
    "    <li><b>len()</b></li>\n",
    "    <li><b>get_dummies()</b></li>\n",
    "    <li><b>startswith()</b></li>\n",
    "    <li><b>endswith()</b></li>\n",
    "    <li><b>replace()</b></li>\n",
    "    <li><b>contains()</b></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8f9ac",
   "metadata": {},
   "source": [
    "#### 1. lower(): \n",
    "<li>It converts all uppercase characters in strings in the dataframe to lower case and returns the lowercase strings in the result.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adfa41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2617de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event'] = weather_df['event'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786be0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716b946",
   "metadata": {},
   "source": [
    "#### 2. upper():\n",
    "<li>It converts all lowercase characters in strings in the dataframe to upper case and returns the uppercase strings in result.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b996e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event'] = weather_df['event'].str.upper()\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086d672",
   "metadata": {},
   "source": [
    "#### 3. islower(): \n",
    "<li>It checks whether all characters in each string in the Data-Frame is in lower case or not, and returns a Boolean value.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event'].str.islower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event'] = weather_df['event'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8149a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event'].str.islower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb1f5d1",
   "metadata": {},
   "source": [
    "#### 4. isupper(): \n",
    "<li>It checks whether all characters in each string in the Data-Frame is in upper case or not, and returns a Boolean value.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event'].str.isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "weather_df['event'][:5] = weather_df['event'][:5].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b09878",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event'].str.isupper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462fcf07",
   "metadata": {},
   "source": [
    "#### 5. isnumeric():\n",
    "<li>It checks whether all characters in each string in the Data-Frame are numeric or not, and returns a Boolean value.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2308c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "series = pd.Series(['one', '1', 'two', '2'])\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8796e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.str.isnumeric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47db0288",
   "metadata": {},
   "source": [
    "#### 6. strip():\n",
    "<li>If there are spaces at the beginning or end of a string, we should trim the strings to eliminate spaces using strip() method.</li>\n",
    "<li>It remove the extra spaces contained by a string in a DataFrame.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5733d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_string = \" Butwal \"\n",
    "print(example_string)\n",
    "print(len(example_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ffa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_example_string = example_string.strip()\n",
    "print(strip_example_string)\n",
    "print(len(strip_example_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data_nan.csv')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d86fe73d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weather_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m weather_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrip_event\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mweather_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weather_df' is not defined"
     ]
    }
   ],
   "source": [
    "weather_df['strip_event'] = weather_df['event'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba805cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event_lenght'] = weather_df['event'].str.len()\n",
    "weather_df['strip_event_length'] = weather_df['strip_event'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78225714",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[['event', 'strip_event', 'event_lenght', 'strip_event_length']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0cc7b",
   "metadata": {},
   "source": [
    "#### 7. split(‘ ‘):\n",
    "<li>It splits each string with the given pattern.</li>\n",
    "<li>Strings are split and the new elements after the performed split operation, are stored in a list.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70370e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fortune_1000.csv', na_values = \" \")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['top_level_domain'] = df['Website'].str.split('.').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Website', 'top_level_domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['top_level_domain'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0786d86",
   "metadata": {},
   "source": [
    "#### 8. len():\n",
    "<li>With the help of len() we can compute the length of each string in DataFrame.</li>\n",
    "<li>If there is empty data in a DataFrame, it returns NaN.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['companyname_length'] = df['company'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['company', 'companyname_length']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866234b9",
   "metadata": {},
   "source": [
    "#### 9. get_dummies(): \n",
    "<li>It returns the DataFrame with One-Hot Encoded values like we can see that it returns boolean value 1 if it exists in relative index or 0 if not exists.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ff5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['strip_event'].str.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936fe69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df['fuel'].str.get_dummies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53501fa7",
   "metadata": {},
   "source": [
    "#### 10. startswith(pattern):\n",
    "<li>It returns true if the element or string in the DataFrame Index starts with the pattern.</li>\n",
    "<li>If you wanted to filter out rows that startswith 'ind' then you can specify df[df[col].str.startswith('ind')</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0589c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df[car_details_df['name'].str.startswith('Maruti')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8051d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Website'].str.startswith('https')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d7983",
   "metadata": {},
   "source": [
    "#### 11. endswith(pattern):\n",
    "<li>It returns true if the element or string in the DataFrame Index ends with the pattern.</li>\n",
    "<li>If you wanted to filter out rows that ends with 'es' then you can specify df[df[col].str.endswith('es')</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649d7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(car_details_df[car_details_df['name'].str.endswith('AC')].shape)\n",
    "car_details_df[car_details_df['name'].str.endswith('AC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85f839",
   "metadata": {},
   "source": [
    "#### 12. replace(a,b):\n",
    "<li>It replaces the value a with the value b.</li>\n",
    "<li>If you wanted to remove white space characters then you can use replace() method as:</li>\n",
    "<code>\n",
    "df[col_name].str.replace(\" \", \"\")\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c805286",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data_nan.csv')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c61940",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event'] = weather_df['event'].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b806a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d7fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['event'] = weather_df['event'].str.replace('Rainy', 'Rain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba307bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90decb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_df['app_start_date'] = appointment_df['app_start_date'].str.replace('/', '-')\n",
    "appointment_df['app_end_date'] = appointment_df['app_end_date'].str.replace('/', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9062a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0272a938",
   "metadata": {},
   "source": [
    "#### 13. contains():\n",
    "<li>contains() method checks whether the string contains a particular substring or not.</li>\n",
    "<li>The function is quite similar to replace() but instead of replacing the string itself it just returns the boolean value True or False.</li>\n",
    "<li>If a substring is present in a string, then it returns boolean value True else False.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_df = pd.read_csv('appointment_schedule.csv')\n",
    "appointment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec87779",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_df['description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87479cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "appointment_df[appointment_df['description'].str.contains('Military', \n",
    "                                                         na = False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5a6dc",
   "metadata": {},
   "source": [
    "#### Handling Missing Values\n",
    "<li>We can use fillna() method in pandas to fill missing values using different ways.</li>\n",
    "<li>We can use interpolation method to make a guess on missing values.</li>\n",
    "<li>We can use dropna() method to drop rows with missing values.</li>\n",
    "<li>We can also fill missing values with the mean value, median value or the mode value depending on the values of columns.</li>\n",
    "<li>Filling missing values with mean and median is appropriate when the column has continuous values.</li>\n",
    "<li>If the data is categorical then filling missing values with mode is a good idea.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74560f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['temperature_fillna_0'] = weather_df['temperature'].fillna(0)\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['temperature_fillna_mean'] = weather_df['temperature'].fillna(weather_df['temperature'].mean())\n",
    "weather_df['temperature_fillna_mean'] = weather_df['temperature_fillna_mean'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfcfe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126cb901",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = weather_df['windspeed'].median()\n",
    "weather_df['windspeed_fillna_median'] = weather_df['windspeed'].fillna(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbcbd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[['day', 'windspeed', 'windspeed_fillna_median']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e060495a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weather_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[43mweather_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m weather_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_fillna_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m  weather_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(mode)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weather_df' is not defined"
     ]
    }
   ],
   "source": [
    "mode = weather_df['event'].mode()[0]\n",
    "weather_df['event_fillna_mode'] =  weather_df['event'].fillna(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[['day', 'event', 'event_fillna_mode']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b01ebc",
   "metadata": {},
   "source": [
    "#### fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec708265",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['ffill_temperature'] = weather_df['temperature'].fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[['day', 'temperature', 'ffill_temperature']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9793078",
   "metadata": {},
   "source": [
    "#### fillna(method = 'bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f70e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0859d35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/7/2017</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        day  temperature  windspeed   event\n",
       "0  1/1/2017         32.0        6.0   Rain \n",
       "1  1/4/2017          NaN        9.0   Sunny\n",
       "2  1/5/2017         -1.0        NaN    Snow\n",
       "3  1/6/2017          NaN        7.0     NaN\n",
       "4  1/7/2017         32.0        NaN    Rain"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv('data/weather_data_nan.csv')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d7bd84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_15276\\2992870978.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  weather_df['bfill_temperature'] = weather_df['temperature'].fillna(method = 'bfill')\n"
     ]
    }
   ],
   "source": [
    "weather_df['bfill_temperature'] = weather_df['temperature'].fillna(method = 'bfill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86b3fe2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>temperature</th>\n",
       "      <th>bfill_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/7/2017</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/8/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/9/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/10/2017</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/11/2017</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/12/2017</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1/13/2017</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1/11/2017</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/14/2017</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          day  temperature  bfill_temperature\n",
       "0    1/1/2017         32.0               32.0\n",
       "1    1/4/2017          NaN               -1.0\n",
       "2    1/5/2017         -1.0               -1.0\n",
       "3    1/6/2017          NaN               32.0\n",
       "4    1/7/2017         32.0               32.0\n",
       "5    1/8/2017          NaN               34.0\n",
       "6    1/9/2017          NaN               34.0\n",
       "7   1/10/2017         34.0               34.0\n",
       "8   1/11/2017         -4.0               -4.0\n",
       "9   1/12/2017         26.0               26.0\n",
       "10  1/13/2017         12.0               12.0\n",
       "11  1/11/2017         -1.0               -1.0\n",
       "12  1/14/2017         40.0               40.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df[['day', 'temperature', 'bfill_temperature']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e2c03",
   "metadata": {},
   "source": [
    "#### Interpolate(Linear Interpolation)\n",
    "<li>method = time</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3864ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['interpolate_temp'] = weather_df['temperature'].interpolate(method = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[['day', 'temperature', 'interpolate_temp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28654597",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('weather_data_nan.csv', parse_dates = ['day'])\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.set_index('day', inplace = True)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['interpolate_time'] = weather_df['temperature'].interpolate(method = 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6690bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b3062",
   "metadata": {},
   "source": [
    "#### dropna()\n",
    "<li>dropna() with how and threshold parameter</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_weather_df = weather_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d823e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[['temperature', 'windspeed']].dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2760f62",
   "metadata": {},
   "source": [
    "#### Handle Missing Values using .replace() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bea681",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.replace('Rainy', 'Rain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d096191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weather_df.replace([-4, -1, np.nan], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c419fb9",
   "metadata": {},
   "source": [
    "#### Replacing Values Using a Dictionary (using columns and without using columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.replace({-1.0 : 0, -4.0 : 0, np.nan: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8906779",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.replace({'temperature': {np.nan: weather_df['temperature'].mean()},\n",
    "                   'windspeed': {np.nan: weather_df['windspeed'].median()},\n",
    "                    'event': {np.nan: 'windy'}\n",
    "                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0dbe0",
   "metadata": {},
   "source": [
    "#### Replacing values using a regex\n",
    "<code>\n",
    "df.replace(original_value, replaced_value, regex = True)\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather_dataset.csv', parse_dates = ['day'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2d994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('day', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08aa33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"[A-Za-z]\",\"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882176fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temperature'].replace(\"[A-Za-z]\", \"\", regex = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "333f2ee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindspeed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[A-Za-z]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, regex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['windspeed'].replace(\"[A-Za-z]\", \"\", regex = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66617916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78d8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('weather_dataset.csv')\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['windspeed'].replace(\"[a-z/a-z]\", \"\", regex = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c047fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['event'] = new_df['event'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.replace({'event': {np.nan: 'Windy', 'Rain': 'Rainy',\n",
    "                         'Snow': 'Snowy'}}, inplace = True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['playing'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7723c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.loc[(new_df['event'] == \"Sunny\") |\n",
    "          (new_df['event'] == \"Windy\"), 'playing'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182e94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7f35d",
   "metadata": {},
   "source": [
    "#### Mapping values of a particular column using replace method\n",
    "<li>Replacing the list of values using another list of values</li>\n",
    "<li>Replacing values of a particular column using a dictionary</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee98c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.replace([0, 1], ['No', 'Yes'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb0a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500df2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1988ee8",
   "metadata": {},
   "source": [
    "#### GroupBy Functions\n",
    "<li>Pandas groupby is used for grouping the data according to the categories and apply a function to the categories.</li>\n",
    "<li>It also helps to aggregate data efficiently.</li>\n",
    "<li>Pandas dataframe.groupby() function is used to split the data into groups based on some criteria.</li>\n",
    "<code>\n",
    "    df.groupby(col_name, as_index, sort, dropna)\n",
    "</code>\n",
    "<li>It uses split, apply, combine principle to create a groupby dataframe.</li>\n",
    "<li>The groupby function accepts multiple parameters. Some of them are as follows:</li>\n",
    "<ol>\n",
    "    <li>col_name(required): the name of column against which you want to group elements.</li>\n",
    "    <li>as_index(optional): default = True, if you want to include groupby column as an index set it        to True else False.</li>\n",
    "    <li>sort(optional): default = True, if you want to sort the group based on keys then keep it as       True else False.</li>\n",
    "    <li>dropna(optional): default = True, if you keep it as false then it will also include Nan values     as a separate group.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('csv_data/weather_data_nan.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event'] = df['event'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef043a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('event')['temperature'].mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2939d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('event', sort = False)['windspeed'].mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ffb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('event', sort = True)[['windspeed', 'temperature']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd211e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('event', sort = True, dropna = False)[['windspeed', 'temperature']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('event', sort = True, as_index = False)[['windspeed', 'temperature']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c395f",
   "metadata": {},
   "source": [
    "### GroupBy Aggregation Functions\n",
    "<li>Here are some of the aggregating functions available in Pandas and quick summary of what it does.</li>\n",
    "<ol>\n",
    "    <li>mean(): Compute mean of groups for numeric columns</li>\n",
    "    <li>sum(): Compute sum of group values for numeric columns</li>\n",
    "    <li>size(): Compute group sizes</li>\n",
    "    <li>count(): Compute count of group</li>\n",
    "    <li>std(): Standard deviation of groups for numeric columns</li>\n",
    "    <li>var(): Compute variance of groups for numeric columns</li>\n",
    "    <li>describe(): Generates descriptive statistics</li>\n",
    "    <li>first(): Compute first of group values</li>\n",
    "    <li>last(): Compute last of group values</li>\n",
    "    <li>nth() : Take nth value, or a subset if n is a list</li>\n",
    "    <li>min(): Compute min of group values</li>\n",
    "    <li>max(): Compute max of group values</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c39503",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = pd.read_csv('csv_data/car_details.csv')\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['brand'] = car_df['name'].str.strip().str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby(['year','brand'], as_index = False)['km_driven'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96838ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby(['year','brand'], as_index = False)['selling_price'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby(['year','brand'], as_index = False)['selling_price'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby(['year','brand'], as_index = False)['selling_price'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c077732",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby(['brand'], as_index = False).nth(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3bf7e",
   "metadata": {},
   "source": [
    "#### Question\n",
    "<li>Read 'car_details.csv' file and create a pandas dataframe from this file.</li>\n",
    "<li>Find the maximum price for each of the car brand.</li>\n",
    "<li>Find the average price for each of the fuel types.</li>\n",
    "<li>Find the average km_driven for each of the seller_types.</li>\n",
    "<li>Find the count of each of the car names.</li>\n",
    "<li>Find the maximum km_driven for each of the owner types.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby('brand')['selling_price'].max().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3fde838",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcar_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuel\u001b[39m\u001b[38;5;124m'\u001b[39m], as_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselling_price\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'car_df' is not defined"
     ]
    }
   ],
   "source": [
    "car_df.groupby(['fuel'], as_index = False)['selling_price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26883aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby(['seller_type'], as_index = False)['km_driven'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby(['brand'], as_index = False)['name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.groupby(['owner'], as_index = False)['km_driven'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a0b50",
   "metadata": {},
   "source": [
    "####  Concatenating DataFrames\n",
    "<li>pandas.concat() function does all the heavy lifting of performing concatenation operations along with an axis</li>\n",
    "<li>If we want to join two individual dataframes and create a combined dataframe out of it, we can use concatenation operation for doing so.</li>\n",
    "<li>We can use concatenation operation along the rows(axis=0) as well as along the columns(axis = 1)</li>\n",
    "\n",
    "**syntax**\n",
    "\n",
    "<code>\n",
    "    pd.concat([df1,df2], axis, keys, ignore_index)\n",
    "</code>\n",
    "\n",
    "<li>df1 and df2 (required) are two dataframes which we want to merge.</li>\n",
    "<li>axis: axis to concatenate along, (possible values; 0(along the rows) and 1 (along the cols) default = 0 (along the rows).</li>\n",
    "<li>keys: sequence to add an identifier to the result indexes; default = None</li>\n",
    "<li>ignore_index: if True, do not use the index values along the concatenation axis; default = False</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345bd33a",
   "metadata": {},
   "source": [
    "#### Concatenating Dataframes along the rows\n",
    "![](images/concat_rows.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210fa3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"Name\": [\"Prabhat\", \"Hari\", \"Shyam\", \"Sita\", \"Mahima\"],\n",
    "                   \"Age\": [24, 34, 50, 32, 18],\n",
    "                   \"Address\": [\"Manigram\", \"Dhanewa\", \"Bardaghat\", \"Manglapur\", \"Bharatpur\"]\n",
    "                   })\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\"Name\": [\"Sunil\", \"Bhawana\", \"Shiva\", \"Himal\", \"Dipen\"],\n",
    "                   \"Age\": [23, 22, 23, 25, 26],\n",
    "                   \"Address\": [\"Kathmandu\", \"Ramechap\", \"Kalangki\", \n",
    "                               \"Chaupatta\", \"Kirtipur\"]\n",
    "                   })\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df1 = pd.concat([df1, df2], axis = 0, ignore_index = True)\n",
    "combined_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e0379",
   "metadata": {},
   "source": [
    "#### Concatenating DataFrames along columns\n",
    "![](images/concat_cols.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29839c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df2 = pd.concat([combined_df1, df3], axis = 1)\n",
    "combined_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef64da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d06a6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "538f1421",
   "metadata": {},
   "source": [
    "#### Merge\n",
    "<li>Pandas has full-featured, high performance in-memory join operations idiomatically very similar to relational databases like SQL.</li>\n",
    "<li>Pandas provides a single function, merge, as the entry point for all standard database join operations between DataFrame objects.</li>\n",
    "<li>The <b>merge()</b> method updates the content of two DataFrame by merging them together, using the specified method(s).</li>\n",
    "<li>We can use the parameters to control which values to keep and which to replace during merge operation.</li>\n",
    "<li>We can specify any type of join we want by using how parameter in merge method.</li>\n",
    "<li>There are four types of join operations. They are :</li>\n",
    "<ol>\n",
    "    <b><li>Inner join</li></b>\n",
    "    <b><li>Left join</li></b>\n",
    "    <b><li>Right join</li></b>\n",
    "    <b><li>Outer join</li></b>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ece457",
   "metadata": {},
   "source": [
    "#### 1. Inner Join\n",
    "![](images/inner_join.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ed12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"name\": [\"Prabhat\", \"Hari\", \"Shyam\", \"Sita\", \"Mahima\", \"Sunil\"],\n",
    "                   \"gender\": [\"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"Male\"],\n",
    "                   \"address\": [\"Manigram\", \"Dhanewa\", \"Bardaghat\", \"Manglapur\", \n",
    "                              \"Bharatpur\", \"Kathmandu\"]})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\"name\": [\"Prabhat\", \"Hari\", \"Shiva\", \"Bhawana\", \"Mahima\", \"Sunil\"],\n",
    "                   \"age\": [24, 34, 50, 32, 18, 23],\n",
    "                   \"height\": [1.6, 1.7, 1.8, 1.43, 1.65, 1.73]})\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_df = pd.merge(df1, df2, on = \"name\", how = \"inner\")\n",
    "inner_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095144e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c47b8516",
   "metadata": {},
   "source": [
    "#### 2. Left Join\n",
    "\n",
    "![](images/left_join.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_df = pd.merge(df1, df2, how = \"left\", on = \"name\")\n",
    "left_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c745229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7582a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b6f196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1879a7d",
   "metadata": {},
   "source": [
    "#### 3. Right Join\n",
    "\n",
    "![](images/right_join.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7436c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_df = pd.merge(df1, df2, how = \"right\", on = \"name\")\n",
    "right_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7be30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34fa6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75961e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11437251",
   "metadata": {},
   "source": [
    "#### 4. Outer Join\n",
    "\n",
    "![](images/outer_join.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf558d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_df = pd.merge(df1, df2, how = \"outer\", on = \"name\")\n",
    "outer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d4b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145281b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8735d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ee9ae1b",
   "metadata": {},
   "source": [
    "#### Crosstab \n",
    "\n",
    "<li>Cross tabulation is used to quantitatively analyze the relationship between multiple variables.</li>\n",
    "<li>Cross tabulations — also referred to as contingency tables or crosstabs.</li>\n",
    "<li>They group variables together and enable researchers to understand the correlation between different variables.<li>\n",
    "<li>When we are doing multivariate analysis then we often came across crosstab() methods in pandas.</li>\n",
    "\n",
    "**Syntax**\n",
    "\n",
    "<code>\n",
    "    pd.crosstab(index, columns, values, margins, margin_names, normalize,aggfunc, dropna)\n",
    "</code>\n",
    "<ol>\n",
    "    <li>index : array-like, Series, or list of arrays/Series, Values to group by in the rows.</li>\n",
    "    <li>columns : array-like, Series, or list of arrays/Series, Values to group by in the columns.</li>\n",
    "    <li>values : array-like, optional, array of values to aggregate according to the factors. Requires `aggfunc` be specified.     </li>\n",
    "    <li>aggfunc : function, optional, If specified, requires `values` be specified as well.</li>\n",
    "    <li>margins : bool, default False, Add row/column margins (subtotals).</li>\n",
    "    <li>margins_name : str, default ‘All’, Name of the row/column that will contain the totals when margins is True.</li>\n",
    "    <li>dropna : bool, default True, Do not include columns whose entries are all NaN.</li>\n",
    "    <li>normalize: </li>\n",
    "    <ol>\n",
    "        <li>If passed ‘all’ or True, will normalize over all values.</li>\n",
    "        <li>If passed ‘index’ will normalize over each row.</li>\n",
    "        <li>If passed ‘columns’ will normalize over each column.</li>\n",
    "        <li>If margins is True, will also normalize margin values.</li>\n",
    "    </ol>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = pd.read_csv('csv_data/car_details.csv')\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12447b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['price_range'] = \"Cheap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dcf068",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.loc[((car_df['selling_price'] > 50000) &\n",
    "           (car_df['selling_price'] < 100000)), 'price_range'] = \"Medium\"\n",
    "\n",
    "car_df.loc[((car_df['selling_price'] > 100000) &\n",
    "           (car_df['selling_price'] < 500000)), 'price_range'] = \"Expensive\"\n",
    "\n",
    "car_df.loc[car_df['selling_price'] > 500000, 'price_range'] = \"Very Expensive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1478cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['price_range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(car_df['price_range'], car_df['fuel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bff1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(car_df['price_range'], car_df['fuel'], margins = True,\n",
    "           margins_name = \"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(car_df['price_range'], car_df['fuel'], margins = True,\n",
    "            normalize = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(car_df['price_range'], car_df['fuel'], margins = True,\n",
    "            normalize = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(car_df['price_range'], car_df['fuel'], margins = True,\n",
    "            normalize = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278baf6a",
   "metadata": {},
   "source": [
    "#### Pivot\n",
    "<li>pivot() method produces pivot table based on 3 columns of the DataFrame. Uses unique values from index / columns and fills with values.</li>\n",
    "\n",
    "    \n",
    "**syntax**\n",
    "<code>\n",
    "pd.pivot(index, columns, values)\n",
    "</code>\n",
    "    \n",
    "<b>Parameters:</b>\n",
    "<ol>\n",
    "    <li>index[ndarray] : Labels to use to make new frame’s index</li>\n",
    "    <li>columns[ndarray] : Labels to use to make new frame’s columns</li>\n",
    "    <li>values[ndarray] : Values to use for populating new frame’s values</li>\n",
    "</ol>\n",
    "\n",
    "**Returns: Reshaped DataFrame**\n",
    "\n",
    "**Exception: ValueError raised if there are any duplicates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['brand'] = car_df['name'].str.strip().str.split(' ').str[0].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72237e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data = car_df, index = 'price_range', columns = 'brand',\n",
    "         values = 'selling_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd438ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.loc[(car_df['brand'] == \"Volkswagen\") &\n",
    "          (car_df['price_range'] == \"Medium\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4939bd3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mpivot_table(data \u001b[38;5;241m=\u001b[39m \u001b[43mcar_df\u001b[49m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseller_type\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m               columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mowner\u001b[39m\u001b[38;5;124m'\u001b[39m, values \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselling_price\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'car_df' is not defined"
     ]
    }
   ],
   "source": [
    "pd.pivot_table(data = car_df, index = 'seller_type',\n",
    "              columns = 'owner', values = \"selling_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60659029",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['selling_price'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5712c0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
